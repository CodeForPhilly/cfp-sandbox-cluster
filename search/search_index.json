{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Cluster Documentation","text":"<p>Welcome, browse sections at the top of the site.</p>"},{"location":"echo-service/","title":"Echo service","text":"<p>Open https://echo-http.sandbox.k8s.phl.io/ to verify cluster connectivity and ingress.</p>"},{"location":"data-warehouse/","title":"Data Warehouse","text":""},{"location":"data-warehouse/#access-via-metabase","title":"Access via Metabase","text":"<p>Metabase is available at https://metabase.sandbox.k8s.phl.io/</p> <p>To be invited, post a request including your email address to the <code>#cfp-data-pipeline</code> Slack channel</p>"},{"location":"data-warehouse/#access-via-psql","title":"Access via psql","text":"<p>The PostgreSQL database port is exposed publically via a <code>NodePort</code> service, which means that port number is open on all nodes in the cluster and automatically proxied to PostgreSQL\u2019s port regardless of which node it is actually running on.</p> <p>As of this writing, one such IP is <code>45.33.79.76</code> but this is subject to change when that node is eventually recycled, so the warehouse could be connected to for administration with a command like:</p> <pre><code>psql -h 45.33.79.76 -p 30432 -U admin -d warehouse\n</code></pre> <p>The password can be found in VaultWarden under the <code>cfp-data-pipeline</code> organization within the item <code>admin @ postgresql database</code>.</p>"},{"location":"data-warehouse/add-user/","title":"Add a user","text":"<p>To add a new PostgreSQL user to the warehouse:</p> <ol> <li>Connect via the <code>admin</code> user</li> <li> <p>Create a new user:</p> <pre><code>CREATE USER myusername WITH ENCRYPTED PASSWORD 'generate_a_password';\n</code></pre> </li> <li> <p>Assign <code>readonly</code> role:</p> <pre><code>GRANT readonly TO myusername;\n</code></pre> </li> </ol>"},{"location":"data-warehouse/initial-setup/","title":"Initial setup","text":"<ol> <li> <p>Create <code>warehouse</code> database in PostgreSQL:</p> <pre><code>CREATE DATABASE warehouse;\n</code></pre> </li> <li> <p>Create <code>readonly</code> warehouse role:</p> <pre><code>CREATE ROLE readonly;\n\n-- Grant access to existing tables\nGRANT USAGE ON SCHEMA public TO readonly;\nGRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly;\n\n-- Grant access to future tables\nALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO readonly;\n</code></pre> </li> <li> <p>Set up user for <code>metabase</code>:</p> <pre><code>CREATE USER metabase WITH ENCRYPTED PASSWORD 'GENERATE_A_PASSWORD_AND_SAVE_IN_VAULT';\nGRANT readonly TO metabase;\n</code></pre> </li> </ol>"},{"location":"development/","title":"Development","text":"<p>The Development section provides content covering:</p> <ul> <li>Overviews of the internal architecture and components</li> <li>Obtaining development environments</li> <li>Executing development workflows</li> <li>Feature implementation guides and examples</li> </ul>"},{"location":"development/features/ingress/","title":"Ingress","text":""},{"location":"development/features/ingress/#exposing-services","title":"Exposing services","text":"<p><code>*.sandbox.k8s.phl.io</code> should be configured to resolve to the cluster\u2019s <code>ingress-nginx</code> service.</p> <p>To route a public hostname to a service in the cluster:</p> <ol> <li>Create an Ingress</li> <li>Apply the annotation <code>kubernetes.io/ingress.class: nginx</code> to associate with the cluster\u2019s main ingress service</li> <li>Apply the annotation <code>cert-manager.io/cluster-issuer: letsencrypt-prod</code> to enable automatic setup of an SSL certificate</li> <li>Assign an unused hostname under <code>.sandbox.k8s.phl.io</code> (every public service should start with one of these)</li> <li>Optionally, CNAME a custom hostname to the <code>.sandbox.k8s.phl.io</code> hostname and add it to the same ingress</li> </ol>"},{"location":"development/features/sealed-secrets/","title":"Sealed Secrets","text":""},{"location":"development/features/sealed-secrets/#prerequisites","title":"Prerequisites","text":"<ul> <li>Configure and deploy a public ingress for sealed-secrets on the cluster</li> <li>Install the <code>kubeseal</code> client command on your local workstation from the latest stable release: https://github.com/bitnami-labs/sealed-secrets/releases</li> </ul>"},{"location":"development/features/sealed-secrets/#configure-public-certificate","title":"Configure public certificate","text":"<p>Place the public URL for the target cluster\u2019s sealed secret\u2019s certificate into the <code>SEALED_SECRETS_CERT</code> environment variable:</p> <pre><code>export SEALED_SECRETS_CERT=https://sealed-secrets.sandbox.k8s.phl.io/v1/cert.pem\n</code></pre>"},{"location":"development/features/sealed-secrets/#encrypt-secrets-to-cluster-repository","title":"Encrypt secrets to cluster repository","text":"<p>Create a Kubernetes <code>Secret</code> manifest containing one or more key+value pair, and then use the <code>kubeseal</code> client to encrypt it into a <code>SealedSecret</code> manifest. The target namespace must be provided and will become part of the encryption such that the secret can only be loaded into that namespace. Commit the sealed secret to the cluster\u2019s repository under the path <code>${project_namespace}.secrets/</code> where it will be added to the cluster\u2019s deployed manifests:</p> <pre><code>kubeseal \\\n    --namespace \"my-project\" \\\n    -f my-secret.yaml \\\n    -w ~/Repositories/my-cluster/my-project.secrets/my-secret.yaml\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":"<p>The Getting Started section provides content covering:</p> <ul> <li>Provisioning and initially deploying the cluster</li> <li>Manual setup steps for included services</li> <li>Onboarding new users into workflows</li> </ul>"},{"location":"getting-started/service-setup/grafana/","title":"Grafana","text":"<p>New clusters will start with the <code>grafana</code> deployment blocked from starting a pod for lack of the <code>grafana-initial-admin</code> secret existing.</p> <p>Creating this secret will enable <code>grafana</code> to start up and create an initial admin login. The secret should be left on the cluster after that as the deployment requires it, but making changes to it will not update any Grafana login unless Grafana\u2019s persistent storage is reset.</p>"},{"location":"getting-started/service-setup/grafana/#creating-grafana-admin-secret","title":"Creating <code>grafana-admin-secret</code>","text":"<p>Use this command to generate a usable secret with a random password:</p> <pre><code>kubectl -n grafana create secret generic grafana-initial-admin \\\n    --from-literal=admin-user=admin \\\n    --from-literal=admin-password=\"$(LC_ALL=C &lt;/dev/urandom tr -dc '[:alnum:]_' | head -c 32)\"\n</code></pre>"},{"location":"getting-started/service-setup/sealed-secrets/","title":"Sealed Secrets","text":"<p>The sealed-secrets controller will automatically generate a public+private keypair for each cluster that will be used to encrypt and decrypt secrets.</p> <p>After any new cluster is provisioned, the generated keypair should be backed up externally (i.e. to a shared VaultWarden/BitWarden collection). With the keypair backed up, secrets can be decrypted locally or restored to a new cluster in the future.</p>"},{"location":"getting-started/service-setup/sealed-secrets/#back-up-generated-keys","title":"Back up generated keys","text":"<p>From the <code>sealed-secrets</code> README.md:</p> <pre><code>kubectl get secret \\\n    -n sealed-secrets \\\n    -l sealedsecrets.bitnami.com/sealed-secrets-key \\\n    -o yaml \\\n&gt; cluster-sealed-secrets-master.key\n</code></pre> <p>Sensitive data!</p> <p>Be sure to keep this file secure and delete from your working directory after uploading it to a secure credentials vault for backup.</p> <p>Do not commit this file to source control</p>"},{"location":"getting-started/service-setup/sealed-secrets/#enable-ingress","title":"Enable ingress","text":"<p>The <code>sealed-secrets</code> helm chart includes an ingress that can be configured to provide a public URL to the cluster\u2019s public certificate that can be used for local <code>kubeseal</code> client operations.</p> <p>To enable the ingress, configure and deploy <code>sealed-secrets/release-values.yaml</code>:</p> sealed-secrets/release-values.yaml <pre><code>ingress:\nenabled: true\nannotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\nhosts:\n    - sealed-secrets.sandbox.k8s.phl.io\ntls:\n    - secretName: sealed-secrets-tls\n    hosts:\n        - sealed-secrets.sandbox.k8s.phl.io\n</code></pre> <p>Once deployed, local <code>kubeseal</code> clients can be configured to use it by setting the <code>SEALED_SECRETS_CERT</code> environment variable:</p> <pre><code>export SEALED_SECRETS_CERT=https://sealed-secrets.sandbox.k8s.phl.io/v1/cert.pem\n</code></pre>"},{"location":"operations/","title":"Operations","text":"<p>The Operations section provides content covering:</p> <ul> <li>Upgrading cluster components</li> <li>Building hosted environments</li> <li>Maintaining hosted environments</li> <li>Backing up and restoring content</li> <li>Monitoring system health</li> </ul>"},{"location":"operations/upgrades/to-0.20/","title":"To 0.20.x","text":"<p><code>cluster-template</code> v0.20.x  brings compatibility with Kubernetes 1.22</p>"},{"location":"operations/upgrades/to-0.20/#upgrade-cert-manager-apis","title":"Upgrade <code>cert-manager</code> APIs","text":"<p>Any manifests defining <code>ClusterIssuer</code> objects must be upgraded to the stable API:</p> <pre><code>diff --git a/cert-manager.issuers.yaml b/cert-manager.issuers.yaml\nindex ebd08997..8dba5834 100644\n--- a/cert-manager.issuers.yaml\n+++ b/cert-manager.issuers.yaml\n@@ -1,4 +1,4 @@\n-apiVersion: cert-manager.io/v1alpha2\n+apiVersion: cert-manager.io/v1\n kind: ClusterIssuer\n</code></pre>"},{"location":"operations/upgrades/to-0.20/#upgrade-cert-manager-crds","title":"Upgrade <code>cert-manager</code> CRDs","text":"<p>If migrating from a pre-1.0 version of <code>cert-manager</code> to a post-1.0 version, you may need to manually delete all CRDs</p>"},{"location":"operations/upgrades/to-0.20/#upgrade-sealed-secrets-ingress-config","title":"Upgrade <code>sealed-secrets</code> ingress config","text":"<p>The newer version of <code>sealed-secrets</code> has a new syntax for configuring its ingress:</p> <pre><code>diff --git a/sealed-secrets/release-values.yaml b/sealed-secrets/release-values.yaml\nindex eb3216c2..3fcef1d3 100644\n--- a/sealed-secrets/release-values.yaml\n+++ b/sealed-secrets/release-values.yaml\n@@ -6,9 +6,5 @@ ingress:\n   annotations:\n     kubernetes.io/ingress.class: nginx\n     cert-manager.io/cluster-issuer: letsencrypt-prod\n-  hosts:\n-    - sealed-secrets.sandbox.k8s.example.com\n-  tls:\n-    - secretName: sealed-secrets-tls\n-      hosts:\n-        - sealed-secrets.sandbox.k8s.example.com\n+  hostname: sealed-secrets.sandbox.k8s.example.com\n+  tls: true\n</code></pre>"},{"location":"operations/upgrades/to-0.20/#upgrade-rbac-apis-for-any-service-account-manifests","title":"Upgrade RBAC APIs for any service account manifests","text":"<pre><code>diff --git a/admins/project-admin.yaml b/admins/project-admin.yaml\nindex dc5c52d0..b3fedfcc 100644\n--- a/admins/project-admin.yaml\n+++ b/admins/project-admin.yaml\n@@ -14,7 +14,7 @@ metadata:\n ---\n\n kind: Role\n-apiVersion: rbac.authorization.k8s.io/v1beta1\n+apiVersion: rbac.authorization.k8s.io/v1\n metadata:\n   name: deployment-admin\n</code></pre>"},{"location":"operations/upgrades/to-0.20/#check-for-deprecated-apis","title":"Check for deprecated APIs","text":"<p>After deploying v0.20.x, check for any locally-defined manifests using deprecated APIs before upgrading the host cluster to Kubernetes v1.22+.</p> <p>Check for deployed objects with deprecated APIs:</p> <pre><code>kubent --target-version 1.22.0\n</code></pre> <p>Check for helm chart snapshots:</p> <pre><code>pluto detect-helm\n</code></pre>"},{"location":"operations/upgrades/to-0.20/#deployment","title":"Deployment","text":"<p>Before deploying an upgrade to v0.20.x, delete existing <code>ingress-nginx</code> jobs to prevent errors about immutable fields being changed:</p> <pre><code>kubectl -n ingress-nginx delete jobs ingress-nginx-admission-create ingress-nginx-admission-patch\n</code></pre> <p>For the same reason, also delete the <code>prometheus-kube-state-metrics</code> deployment:</p> <pre><code>kubectl -n prometheus delete deployment prometheus-kube-state-metrics\n</code></pre>"},{"location":"operations/upgrades/to-1.0/","title":"To 1.0.x","text":"<p>If upgrading from a version earlier than v0.20.x, follow the notes for upgrading to v0.20.x instead.</p>"},{"location":"operations/upgrades/to-1.0/#deployment","title":"Deployment","text":"<p>Before deploying an upgrade to v1.0.x, delete existing <code>ingress-nginx</code> jobs to prevent errors about immutable fields being changed:</p> <pre><code>kubectl -n ingress-nginx delete jobs ingress-nginx-admission-create ingress-nginx-admission-patch\n</code></pre>"}]}