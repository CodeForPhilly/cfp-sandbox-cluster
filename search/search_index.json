{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cluster Documentation \u00b6 Welcome, browse sections at the top of the site.","title":"Cluster Documentation"},{"location":"#cluster-documentation","text":"Welcome, browse sections at the top of the site.","title":"Cluster Documentation"},{"location":"echo-service/","text":"Echo service \u00b6 Open https://echo-http.sandbox.k8s.phl.io/ to verify cluster connectivity and ingress.","title":"Echo service"},{"location":"echo-service/#echo-service","text":"Open https://echo-http.sandbox.k8s.phl.io/ to verify cluster connectivity and ingress.","title":"Echo service"},{"location":"development/","text":"Development \u00b6 The Development section provides content covering: Overviews of the internal architecture and components Obtaining development environments Executing development workflows Feature implementation guides and examples","title":"Development"},{"location":"development/#development","text":"The Development section provides content covering: Overviews of the internal architecture and components Obtaining development environments Executing development workflows Feature implementation guides and examples","title":"Development"},{"location":"development/features/ingress/","text":"Ingress \u00b6 Exposing services \u00b6 *.sandbox.k8s.phl.io should be configured to resolve to the cluster\u2019s ingress-nginx service. To route a public hostname to a service in the cluster: Create an Ingress Apply the annotation kubernetes.io/ingress.class: nginx to associate with the cluster\u2019s main ingress service Apply the annotation cert-manager.io/cluster-issuer: letsencrypt-prod to enable automatic setup of an SSL certificate Assign an unused hostname under .sandbox.k8s.phl.io (every public service should start with one of these) Optionally, CNAME a custom hostname to the .sandbox.k8s.phl.io hostname and add it to the same ingress","title":"Ingress"},{"location":"development/features/ingress/#ingress","text":"","title":"Ingress"},{"location":"development/features/ingress/#exposing-services","text":"*.sandbox.k8s.phl.io should be configured to resolve to the cluster\u2019s ingress-nginx service. To route a public hostname to a service in the cluster: Create an Ingress Apply the annotation kubernetes.io/ingress.class: nginx to associate with the cluster\u2019s main ingress service Apply the annotation cert-manager.io/cluster-issuer: letsencrypt-prod to enable automatic setup of an SSL certificate Assign an unused hostname under .sandbox.k8s.phl.io (every public service should start with one of these) Optionally, CNAME a custom hostname to the .sandbox.k8s.phl.io hostname and add it to the same ingress","title":"Exposing services"},{"location":"getting-started/","text":"Getting Started \u00b6 The Getting Started section provides content covering: Provisioning and initially deploying the cluster Manual setup steps for included services Onboarding new users into workflows","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"The Getting Started section provides content covering: Provisioning and initially deploying the cluster Manual setup steps for included services Onboarding new users into workflows","title":"Getting Started"},{"location":"getting-started/service-setup/grafana/","text":"Grafana \u00b6 New clusters will start with the grafana deployment blocked from starting a pod for lack of the grafana-initial-admin secret existing. Creating this secret will enable grafana to start up and create an initial admin login. The secret should be left on the cluster after that as the deployment requires it, but making changes to it will not update any Grafana login unless Grafana\u2019s persistent storage is reset. Creating grafana-admin-secret \u00b6 Use this command to generate a usable secret with a random password: kubectl -n grafana create secret generic grafana-initial-admin \\ --from-literal = admin-user = admin \\ --from-literal = admin-password = \" $( cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1 ) \"","title":"Grafana"},{"location":"getting-started/service-setup/grafana/#grafana","text":"New clusters will start with the grafana deployment blocked from starting a pod for lack of the grafana-initial-admin secret existing. Creating this secret will enable grafana to start up and create an initial admin login. The secret should be left on the cluster after that as the deployment requires it, but making changes to it will not update any Grafana login unless Grafana\u2019s persistent storage is reset.","title":"Grafana"},{"location":"getting-started/service-setup/grafana/#creating-grafana-admin-secret","text":"Use this command to generate a usable secret with a random password: kubectl -n grafana create secret generic grafana-initial-admin \\ --from-literal = admin-user = admin \\ --from-literal = admin-password = \" $( cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1 ) \"","title":"Creating grafana-admin-secret"},{"location":"getting-started/service-setup/sealed-secrets/","text":"Sealed Secrets \u00b6 The sealed-secrets controller will automatically generate a public+private keypair for each cluster that will be used to encrypt and decrypt secrets. After any new cluster is provisioned, the generated keypair should be backed up externally (i.e. to a shared VaultWarden/BitWarden collection). With the keypair backed up, secrets can be decrypted locally or restored to a new cluster in the future. Back up generated keys \u00b6 From the sealed-secrets README.md : kubectl get secret \\ -n sealed-secrets \\ -l sealedsecrets.bitnami.com/sealed-secrets-key \\ -o yaml \\ > cluster-sealed-secrets-master.key Sensitive data! Be sure to keep this file secure and delete from your working directory after uploading it to a secure credentials vault for backup. Do not commit this file to source control","title":"Sealed Secrets"},{"location":"getting-started/service-setup/sealed-secrets/#sealed-secrets","text":"The sealed-secrets controller will automatically generate a public+private keypair for each cluster that will be used to encrypt and decrypt secrets. After any new cluster is provisioned, the generated keypair should be backed up externally (i.e. to a shared VaultWarden/BitWarden collection). With the keypair backed up, secrets can be decrypted locally or restored to a new cluster in the future.","title":"Sealed Secrets"},{"location":"getting-started/service-setup/sealed-secrets/#back-up-generated-keys","text":"From the sealed-secrets README.md : kubectl get secret \\ -n sealed-secrets \\ -l sealedsecrets.bitnami.com/sealed-secrets-key \\ -o yaml \\ > cluster-sealed-secrets-master.key Sensitive data! Be sure to keep this file secure and delete from your working directory after uploading it to a secure credentials vault for backup. Do not commit this file to source control","title":"Back up generated keys"}]}